{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "002e27fe-1daa-4aef-adf5-e5b9ae4b1dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/USER/Desktop/credit')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -q dvc==3.53.2 joblib matplotlib \n",
    "\n",
    "from pathlib import Path\n",
    "ROOT = Path.cwd() if Path.cwd().name==\"credit\" else Path.cwd().parent\n",
    "ROOT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d495b-6d8d-429e-81ce-75c4a00d3174",
   "metadata": {},
   "source": [
    "# Дерево папок + сырой датасет под DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "194bd6aa-215a-4b8f-b74b-d830b8920ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/USER/Desktop/credit/data/raw/UCI_Credit_Card.csv'),\n",
       " True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "# создадим нужные папки\n",
    "for p in [\"data/raw\", \"data/processed\", \"models\", \"src/data\", \"src/models\"]:\n",
    "    (ROOT / p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# положи исходный CSV в data/raw (если его там нет)\n",
    "raw_csv = ROOT / \"data\" / \"raw\" / \"UCI_Credit_Card.csv\"\n",
    "if not raw_csv.exists():\n",
    "    # если файл лежит рядом с ноутбуком/где-то ещё — поправь путь ниже и скопируй\n",
    "    possible = ROOT / \"UCI_Credit_Card.csv\"\n",
    "    if possible.exists():\n",
    "        shutil.copy2(possible, raw_csv)\n",
    "\n",
    "raw_csv, raw_csv.exists()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038ec71-a983-44bf-af00-203d9e56b17d",
   "metadata": {},
   "source": [
    "## DVC init + добавим сырой CSV в DVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a81d18f-0eb9-4a16-9800-bd4e046d3168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> dvc init -q \n",
      " \n",
      "> dvc add data/raw/UCI_Credit_Card.csv \n",
      " \n",
      "To track the changes with git, run:\n",
      "\n",
      "\tgit add 'data\\raw\\UCI_Credit_Card.csv.dvc'\n",
      "\n",
      "To enable auto staging, run:\n",
      "\n",
      "\tdvc config core.autostage true\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='dvc add data/raw/UCI_Credit_Card.csv', returncode=0, stdout=\"\\nTo track the changes with git, run:\\n\\n\\tgit add 'data\\\\raw\\\\UCI_Credit_Card.csv.dvc'\\n\\nTo enable auto staging, run:\\n\\n\\tdvc config core.autostage true\\n\", stderr='\\\\u280b Checking graph\\n\\n')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess, sys\n",
    "\n",
    "def sh(cmd):\n",
    "    r = subprocess.run(cmd, cwd=ROOT, shell=True, text=True, capture_output=True)\n",
    "    print(\">\", cmd, \"\\n\", r.stdout or r.stderr); \n",
    "    return r\n",
    "\n",
    "sh(\"dvc init -q\")\n",
    "# добавим сырой датасет под контроль DVC (в гит уйдёт .dvc-файл, сам csv — в .gitignore)\n",
    "sh(\"dvc add data/raw/UCI_Credit_Card.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea095b1d-afff-41a8-9b7b-2274fe8654ef",
   "metadata": {},
   "source": [
    "## Скрипт src/models/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d99207d-21ed-434b-8a4f-b1053d054975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/USER/Desktop/credit/src/models/train.py')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = r\"\"\"\n",
    "import json, argparse\n",
    "from pathlib import Path\n",
    "import joblib, pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "TARGET = \"default.payment.next.month\"\n",
    "\n",
    "def make_preprocess(X):\n",
    "    all_cols = X.columns.tolist()\n",
    "    cat = [c for c in [\"SEX\",\"EDUCATION\",\"MARRIAGE\"] if c in all_cols] + [c for c in all_cols if c.startswith(\"PAY_\")]\n",
    "    cat = sorted(list(dict.fromkeys(cat)))\n",
    "    num = [c for c in all_cols if c not in cat]\n",
    "\n",
    "    num_tf = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                       (\"scaler\", StandardScaler())])\n",
    "    cat_tf = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                       (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "    return ColumnTransformer([(\"num\", num_tf, num), (\"cat\", cat_tf, cat)])\n",
    "\n",
    "def main(train_path, test_path, model_out, metrics_out):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test  = pd.read_csv(test_path)\n",
    "    for df in (train, test):\n",
    "        if \"ID\" in df.columns: df.drop(columns=[\"ID\"], inplace=True)\n",
    "\n",
    "    X_train, y_train = train.drop(columns=[TARGET]), train[TARGET]\n",
    "    X_test,  y_test  = test.drop(columns=[TARGET]),  test[TARGET]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", make_preprocess(X_train)),\n",
    "        (\"clf\", GradientBoostingClassifier(learning_rate=0.1, n_estimators=150, random_state=42))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "    y_pred  = pipe.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": \"GradientBoostingClassifier\",\n",
    "        \"model_params\": {\"learning_rate\": 0.1, \"n_estimators\": 150},\n",
    "        \"roc_auc\": float(roc_auc_score(y_test, y_proba)),\n",
    "        \"precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_test, y_pred, zero_division=0))\n",
    "    }\n",
    "\n",
    "    model_out = Path(model_out); model_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    metrics_out = Path(metrics_out); metrics_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(pipe, model_out)\n",
    "    Path(metrics_out).write_text(json.dumps(metrics, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--train\", required=True)\n",
    "    p.add_argument(\"--test\", required=True)\n",
    "    p.add_argument(\"--model-out\", required=True)\n",
    "    p.add_argument(\"--metrics-out\", required=True)\n",
    "    args = p.parse_args()\n",
    "    main(args.train, args.test, args.model_out, args.metrics_out)\n",
    "\"\"\"\n",
    "path = ROOT / \"src\" / \"models\" / \"train.py\"\n",
    "path.write_text(code, encoding=\"utf-8\"); path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d055f868-ec9f-458b-b88a-f2d95efbad5c",
   "metadata": {},
   "source": [
    "## Создаём dvc.yaml (2 стадии)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd6b0316-1286-4b7e-b847-90b6086f9af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/USER/Desktop/credit/dvc.yaml')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dvc_yaml = f\"\"\"\n",
    "stages:\n",
    "  prepare:\n",
    "    cmd: python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
    "    deps:\n",
    "    - src/data/make_dataset.py\n",
    "    - data/raw/UCI_Credit_Card.csv\n",
    "    outs:\n",
    "    - data/processed/train.csv\n",
    "    - data/processed/test.csv\n",
    "\n",
    "  train:\n",
    "    cmd: python src/models/train.py --train data/processed/train.csv --test data/processed/test.csv --model-out models/credit_default_model.pkl --metrics-out models/metrics.json\n",
    "    deps:\n",
    "    - src/models/train.py\n",
    "    - data/processed/train.csv\n",
    "    - data/processed/test.csv\n",
    "    outs:\n",
    "    - models/credit_default_model.pkl\n",
    "    metrics:\n",
    "    - models/metrics.json:\n",
    "        cache: false\n",
    "\"\"\"\n",
    "p = (ROOT / \"dvc.yaml\")\n",
    "p.write_text(dvc_yaml, encoding=\"utf-8\"); p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7775695-39c3-4d6e-a1f8-d46384fd9b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> dvc repro \n",
      " 'data\\raw\\UCI_Credit_Card.csv.dvc' didn't change, skipping\n",
      "Running stage 'prepare':\n",
      "> python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
      "\n",
      "{\n",
      "  \"model\": \"GradientBoostingClassifier\",\n",
      "  \"model_params\": {\n",
      "    \"learning_rate\": 0.1,\n",
      "    \"n_estimators\": 150\n",
      "  },\n",
      "  \"roc_auc\": 0.7705572956671517,\n",
      "  \"precision\": 0.6647230320699709,\n",
      "  \"recall\": 0.3436322532027129,\n",
      "  \"f1\": 0.45305514157973176\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# пересоберёт обе стадии, положит артефакты и метрики\n",
    "sh(\"dvc repro\")\n",
    "print((ROOT/\"models\"/\"metrics.json\").read_text()[:250])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "66b5ebcb-a18d-4dd8-bb83-d63aae5b0e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> git add notebooks/04_dvc_pipeline.ipynb \n",
      " warning: in the working copy of 'notebooks/04_dvc_pipeline.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "\n",
      "> git commit -m \"wip(dvc): update 04_dvc_pipeline notebook\" \n",
      " [main e24e48a] wip(dvc): update 04_dvc_pipeline notebook\n",
      " 1 file changed, 75 insertions(+), 11 deletions(-)\n",
      "\n",
      "> git pull --rebase origin main \n",
      " From https://github.com/pero1x1/credit\n",
      " * branch            main       -> FETCH_HEAD\n",
      "Rebasing (1/5)\n",
      "Rebasing (2/5)\n",
      "Rebasing (3/5)\n",
      "Rebasing (4/5)\n",
      "Rebasing (5/5)\n",
      "Successfully rebased and updated refs/heads/main.\n",
      "\n",
      "> git push \n",
      " To https://github.com/pero1x1/credit.git\n",
      "   a824c4a..f57feeb  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='git push', returncode=0, stdout='', stderr='To https://github.com/pero1x1/credit.git\\n   a824c4a..f57feeb  main -> main\\n')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh(\"git add notebooks/04_dvc_pipeline.ipynb\")\n",
    "sh('git commit -m \"wip(dvc): update 04_dvc_pipeline notebook\"')\n",
    "\n",
    "sh(\"git pull --rebase origin main\")\n",
    "\n",
    "sh(\"git push\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e815b40-6af3-4144-bcca-92e02e50850f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> git add -A \n",
      " warning: in the working copy of 'notebooks/04_dvc_pipeline.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "\n",
      "> git commit -m \"build(dvc): init + dvc.yaml (prepare/train) + data/raw under DVC + reproducible training\" \n",
      " [main 493a750] build(dvc): init + dvc.yaml (prepare/train) + data/raw under DVC + reproducible training\n",
      " 1 file changed, 20 insertions(+), 90 deletions(-)\n",
      "\n",
      "> git push \n",
      " To https://github.com/pero1x1/credit.git\n",
      "   f57feeb..493a750  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='git push', returncode=0, stdout='', stderr='To https://github.com/pero1x1/credit.git\\n   f57feeb..493a750  main -> main\\n')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# не забываем requirements и .gitignore обновить, если нужно\n",
    "req = ROOT/\"requirements.txt\"\n",
    "txt = req.read_text(encoding=\"utf-8\") if req.exists() else \"\"\n",
    "for line in [\"dvc==3.53.2\", \"joblib\"]:\n",
    "    if line not in txt:\n",
    "        txt += (\"\" if txt.endswith(\"\\n\") else \"\\n\") + line + \"\\n\"\n",
    "req.write_text(txt, encoding=\"utf-8\")\n",
    "\n",
    "sh(\"git add -A\")\n",
    "sh('git commit -m \"build(dvc): init + dvc.yaml (prepare/train) + data/raw under DVC + reproducible training\"')\n",
    "sh(\"git push\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db086192-e7be-42be-98e3-ce048725f36b",
   "metadata": {},
   "source": [
    "## dvc.yaml + params.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1bacd20-23c7-442e-beb1-f963a8b4b31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  prepare:\n",
      "    cmd: python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
      "    deps:\n",
      "      - src/data/make_dataset.py\n",
      "      - data/raw/UCI_Credit_Card.csv\n",
      "    outs:\n",
      "      - data/processed/train.csv\n",
      "      - data/processed/test.csv\n",
      "\n",
      "  train:\n",
      "    cmd: python src/models/train.py data/processed/train.csv data/processed/test.csv models/\n",
      "    deps:\n",
      "      - src/models/train.py\n"
     ]
    }
   ],
   "source": [
    "import pathlib, textwrap, subprocess, json, sys, os, yaml\n",
    "\n",
    "ROOT = pathlib.Path.cwd() if pathlib.Path.cwd().name==\"credit\" else pathlib.Path.cwd().parent\n",
    "\n",
    "def sh(cmd):\n",
    "    r = subprocess.run(cmd, cwd=ROOT, shell=True, text=True, capture_output=True)\n",
    "    print(\">\", cmd, \"\\n\", r.stdout or r.stderr); return r\n",
    "\n",
    "# --- params.yaml (чтобы train.py мог читать гиперпараметры)\n",
    "params = {\n",
    "    \"model\": {\n",
    "        \"type\": \"GradientBoostingClassifier\",\n",
    "        \"n_estimators\": 150,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"random_state\": 42\n",
    "    }\n",
    "}\n",
    "(ROOT / \"params.yaml\").write_text(yaml.safe_dump(params, sort_keys=False), encoding=\"utf-8\")\n",
    "\n",
    "# --- dvc.yaml (2 стадии: prepare -> train)\n",
    "dvc_yaml = textwrap.dedent(\"\"\"\n",
    "stages:\n",
    "  prepare:\n",
    "    cmd: python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
    "    deps:\n",
    "      - src/data/make_dataset.py\n",
    "      - data/raw/UCI_Credit_Card.csv\n",
    "    outs:\n",
    "      - data/processed/train.csv\n",
    "      - data/processed/test.csv\n",
    "\n",
    "  train:\n",
    "    cmd: python src/models/train.py data/processed/train.csv data/processed/test.csv models/\n",
    "    deps:\n",
    "      - src/models/train.py\n",
    "      - data/processed/train.csv\n",
    "      - data/processed/test.csv\n",
    "      - params.yaml\n",
    "    outs:\n",
    "      - models/credit_default_model.pkl\n",
    "    metrics:\n",
    "      - models/metrics.json:\n",
    "          cache: false\n",
    "\"\"\").strip()\n",
    "(ROOT / \"dvc.yaml\").write_text(dvc_yaml, encoding=\"utf-8\")\n",
    "\n",
    "print((ROOT/\"dvc.yaml\").read_text()[:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bc7452b-843c-44f7-ad84-1b5da8451d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.py обновлён под params.yaml\n"
     ]
    }
   ],
   "source": [
    "# патчим src/models/train.py: чтение params.yaml и запись metrics.json\n",
    "from pathlib import Path\n",
    "p = ROOT/\"src/models/train.py\"\n",
    "code = p.read_text(encoding=\"utf-8\")\n",
    "\n",
    "if \"yaml.safe_load\" not in code:\n",
    "    patched = \"\"\"\n",
    "import sys, json, joblib, pandas as pd\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main(train_path, test_path, out_dir):\n",
    "    params = yaml.safe_load(open('params.yaml'))['model']\n",
    "    model_type = params.get('type', 'GradientBoostingClassifier')\n",
    "\n",
    "    X_train = pd.read_csv(train_path).drop(columns=['default.payment.next.month'])\n",
    "    y_train = pd.read_csv(train_path)['default.payment.next.month']\n",
    "    X_test  = pd.read_csv(test_path).drop(columns=['default.payment.next.month'])\n",
    "    y_test  = pd.read_csv(test_path)['default.payment.next.month']\n",
    "\n",
    "    if model_type == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=params.get('n_estimators', 200),\n",
    "            max_depth=params.get('max_depth', None),\n",
    "            class_weight=params.get('class_weight', None),\n",
    "            random_state=params.get('random_state', 42)\n",
    "        )\n",
    "    else:\n",
    "        model = GradientBoostingClassifier(\n",
    "            n_estimators=params.get('n_estimators', 150),\n",
    "            learning_rate=params.get('learning_rate', 0.1),\n",
    "            random_state=params.get('random_state', 42)\n",
    "        )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    proba = model.predict_proba(X_test)[:,1] if hasattr(model,'predict_proba') else model.decision_function(X_test)\n",
    "    pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "    metrics = {\n",
    "        \"roc_auc\": float(roc_auc_score(y_test, proba)),\n",
    "        \"precision\": float(precision_score(y_test, pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_test, pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_test, pred, zero_division=0)),\n",
    "        \"model\": model.__class__.__name__,\n",
    "        \"model_params\": {k: getattr(model, k, None) for k in ['n_estimators','learning_rate','max_depth','class_weight']}\n",
    "    }\n",
    "\n",
    "    out = Path(out_dir); out.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(model, out/'credit_default_model.pkl')\n",
    "    (out/'metrics.json').write_text(json.dumps(metrics, indent=2), encoding='utf-8')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_path, test_path, out_dir = sys.argv[1], sys.argv[2], sys.argv[3]\n",
    "    main(train_path, test_path, out_dir)\n",
    "\"\"\"\n",
    "    p.write_text(patched, encoding=\"utf-8\")\n",
    "    print(\"train.py обновлён под params.yaml\")\n",
    "else:\n",
    "    print(\"train.py уже читает params.yaml — ок\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7251cec8-e497-4300-923f-a4c03efe1a0b",
   "metadata": {},
   "source": [
    "## Первый прогон пайплайна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4daccc15-acb1-4e1b-9042-681a4bf4ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> dvc repro \n",
      " 'data\\raw\\UCI_Credit_Card.csv.dvc' didn't change, skipping\n",
      "Running stage 'prepare':\n",
      "> python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
      "\n",
      "> dvc metrics show -T \n",
      " Revision    Path                 f1       model                       model_params.learning_rate    model_params.n_estimators    precision    recall    roc_auc\n",
      "workspace   models\\metrics.json  0.45306  GradientBoostingClassifier  0.1                           150                          0.66472      0.34363   0.77056\n",
      "\n",
      "> dvc dag \n",
      " +----------------------------------+ \n",
      "| data\\raw\\UCI_Credit_Card.csv.dvc | \n",
      "+----------------------------------+ \n",
      "                  *                  \n",
      "                  *                  \n",
      "                  *                  \n",
      "            +---------+              \n",
      "            | prepare |              \n",
      "            +---------+              \n",
      "                  *                  \n",
      "                  *                  \n",
      "                  *                  \n",
      "              +-------+              \n",
      "              | train |              \n",
      "              +-------+              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='dvc dag', returncode=0, stdout='+----------------------------------+ \\n| data\\\\raw\\\\UCI_Credit_Card.csv.dvc | \\n+----------------------------------+ \\n                  *                  \\n                  *                  \\n                  *                  \\n            +---------+              \\n            | prepare |              \\n            +---------+              \\n                  *                  \\n                  *                  \\n                  *                  \\n              +-------+              \\n              | train |              \\n              +-------+              \\n', stderr='')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh(\"dvc repro\")            # выполнит prepare -> train, создаст dvc.lock\n",
    "sh(\"dvc metrics show -T\")  # покажет models/metrics.json\n",
    "sh(\"dvc dag\")              # граф стадий\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b31ed6-d5c3-404d-b56a-e6aa977ecc69",
   "metadata": {},
   "source": [
    "## Коммит и пуш"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67469cb1-5283-4ed7-85e3-63d61dc652e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> git add -A \n",
      " warning: in the working copy of 'notebooks/04_dvc_pipeline.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "warning: in the working copy of 'notebooks/Untitled.ipynb', LF will be replaced by CRLF the next time Git touches it\n",
      "\n",
      "> git commit -m \"build(dvc): pipeline prepare/train + first repro; lock + metrics\" \n",
      " [main 71f91b0] build(dvc): pipeline prepare/train + first repro; lock + metrics\n",
      " 5 files changed, 204 insertions(+), 69 deletions(-)\n",
      " create mode 100644 notebooks/Untitled.ipynb\n",
      " create mode 100644 params.yaml\n",
      "\n",
      "> git push \n",
      " To https://github.com/pero1x1/credit.git\n",
      "   493a750..71f91b0  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='git push', returncode=0, stdout='', stderr='To https://github.com/pero1x1/credit.git\\n   493a750..71f91b0  main -> main\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sh(\"git add -A\")\n",
    "sh('git commit -m \"build(dvc): pipeline prepare/train + first repro; lock + metrics\"')\n",
    "sh(\"git push\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835d7d5b-87a8-46ce-8819-6ecdd7a78dae",
   "metadata": {},
   "source": [
    "## DVC Experiments (params + repro + exp show) и локальный remote\n",
    "\n",
    "1) Перевожу `train.py` на чтение гиперпараметров из `params.yaml`.\n",
    "2) В `dvc.yaml` подключаю `params` для стадии `train`.\n",
    "3) Делаю пару экспериментов через `dvc exp run -S ...` и сравниваю метрики.\n",
    "4) Настраиваю локальный DVC remote (папка `dvcstore/`) и пушу артефакты.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20b50027-9b18-4a08-a639-73999456e869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/USER/Desktop/credit')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess, pathlib, sys\n",
    "\n",
    "ROOT = pathlib.Path.cwd() if pathlib.Path.cwd().name==\"credit\" else pathlib.Path.cwd().parent\n",
    "\n",
    "def sh(cmd):\n",
    "    r = subprocess.run(cmd, cwd=ROOT, shell=True, text=True, capture_output=True)\n",
    "    print(\">\", cmd, \"\\n\", r.stdout or r.stderr)\n",
    "    return r\n",
    "\n",
    "ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418234ff-8f96-4038-b589-8ea36faaa9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> C:\\Users\\USER\\Desktop\\credit\\.venv\\Scripts\\python.exe -m pip install -q pyyaml dvc==3.53.2 \n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='C:\\\\Users\\\\USER\\\\Desktop\\\\credit\\\\.venv\\\\Scripts\\\\python.exe -m pip install -q pyyaml dvc==3.53.2', returncode=0, stdout='', stderr='')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req = (ROOT / \"requirements.txt\")\n",
    "text = req.read_text(encoding=\"utf-8\") if req.exists() else \"\"\n",
    "need = [\"pyyaml\", \"dvc==3.53.2\"]\n",
    "for pkg in need:\n",
    "    if pkg not in text.lower():\n",
    "        text += (\"\\n\" + pkg + \"\\n\")\n",
    "req.write_text(text.strip()+\"\\n\", encoding=\"utf-8\")\n",
    "\n",
    "# локально для ядра\n",
    "sh(f\"{ROOT/' .venv/Scripts/python' if (ROOT/'.venv/Scripts/python').exists() else sys.executable} -m pip install -q pyyaml dvc==3.53.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "998fc3eb-8c11-4207-8a23-b567c37eaddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/USER/Desktop/credit/src/models/train.py')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = r'''\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import joblib, pandas as pd\n",
    "import yaml\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "TARGET = \"default.payment.next.month\"\n",
    "\n",
    "def make_preprocess(df):\n",
    "    all_cols = list(df.columns)\n",
    "    cat = [c for c in [\"SEX\",\"EDUCATION\",\"MARRIAGE\"] if c in all_cols] + [c for c in all_cols if c.startswith(\"PAY_\")]\n",
    "    num = [c for c in all_cols if c not in cat]\n",
    "\n",
    "    num_tf = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                       (\"scaler\",  StandardScaler())])\n",
    "\n",
    "    cat_tf = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "                       (\"onehot\",  OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "    return ColumnTransformer([(\"num\",  num_tf, num), (\"cat\",  cat_tf, cat)])\n",
    "\n",
    "def train(train_path, test_path, model_out, metrics_out):\n",
    "    # читаю параметры из params.yaml\n",
    "    P = yaml.safe_load((Path(__file__).parents[1] / \"params.yaml\").read_text(encoding=\"utf-8\"))\n",
    "    lr = float(P[\"model\"][\"learning_rate\"])\n",
    "    n_est = int(P[\"model\"][\"n_estimators\"])\n",
    "\n",
    "    train = pd.read_csv(train_path)\n",
    "    test  = pd.read_csv(test_path)\n",
    "    if \"ID\" in train.columns: train.drop(columns=[\"ID\"], inplace=True)\n",
    "    if \"ID\" in test.columns:  test.drop(columns=[\"ID\"],  inplace=True)\n",
    "\n",
    "    X_train, y_train = train.drop(columns=[TARGET]), train[TARGET]\n",
    "    X_test,  y_test  = test.drop(columns=[TARGET]),  test[TARGET]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocess\", make_preprocess(train)),\n",
    "        (\"clf\", GradientBoostingClassifier(learning_rate=lr, n_estimators=n_est, random_state=42)),\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": \"GradientBoostingClassifier\",\n",
    "        \"model_params\": {\"learning_rate\": lr, \"n_estimators\": n_est},\n",
    "        \"roc_auc\":  float(roc_auc_score(y_test, y_prob)),\n",
    "        \"precision\": float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_test, y_pred, zero_division=0)),\n",
    "    }\n",
    "\n",
    "    Path(model_out).parent.mkdir(parents=True, exist_ok=True)\n",
    "    Path(metrics_out).parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(pipe, model_out)\n",
    "    Path(metrics_out).write_text(__import__(\"json\").dumps(metrics, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--train\", required=True)\n",
    "    ap.add_argument(\"--test\",  required=True)\n",
    "    ap.add_argument(\"--model-out\", required=True)\n",
    "    ap.add_argument(\"--metrics-out\", required=True)\n",
    "    args = ap.parse_args()\n",
    "    train(args.train, args.test, args.model_out, args.metrics_out)\n",
    "'''\n",
    "p = ROOT / \"src\" / \"models\" / \"train.py\"\n",
    "p.write_text(code.strip()+\"\\n\", encoding=\"utf-8\")\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2ff4e44-610f-477f-bcf0-f191ce3ada8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': {'type': 'GradientBoostingClassifier',\n",
       "  'n_estimators': 150,\n",
       "  'learning_rate': 0.1,\n",
       "  'random_state': 42}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml, io\n",
    "params_path = ROOT / \"params.yaml\"\n",
    "P = {\"model\": {\"learning_rate\": 0.10, \"n_estimators\": 150}}\n",
    "if params_path.exists():\n",
    "    P0 = yaml.safe_load(params_path.read_text(encoding=\"utf-8\")) or {}\n",
    "    # аккуратно обновляю только нужные ключи\n",
    "    P0.setdefault(\"model\", {})\n",
    "    P0[\"model\"].setdefault(\"learning_rate\", 0.10)\n",
    "    P0[\"model\"].setdefault(\"n_estimators\", 150)\n",
    "    P = P0\n",
    "params_path.write_text(yaml.safe_dump(P, sort_keys=False, allow_unicode=True), encoding=\"utf-8\")\n",
    "P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2c0b2f4-aa37-4746-97a1-8c57a3f9ffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages:\n",
      "  prepare:\n",
      "    cmd: python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
      "    deps:\n",
      "      - src/data/make_dataset.py\n",
      "      - data/raw/UCI_Credit_Card.csv\n",
      "    outs:\n",
      "      - data/processed/train.csv\n",
      "      - data/processed/test.csv\n",
      "\n",
      "  train:\n",
      "    cmd: python src/models/train.py data/processed/train.csv data/processed/test.csv models/\n",
      "    deps:\n",
      "      - src/models/train.py ...\n"
     ]
    }
   ],
   "source": [
    "dvc_yaml = (ROOT / \"dvc.yaml\").read_text(encoding=\"utf-8\")\n",
    "if \"params:\" not in dvc_yaml:\n",
    "    dvc_yaml = dvc_yaml.replace(\n",
    "        \"train:\\n  cmd:\",\n",
    "        \"train:\\n  params:\\n  - params.yaml:\\n    - model.learning_rate\\n    - model.n_estimators\\n  cmd:\"\n",
    "    )\n",
    "    (ROOT / \"dvc.yaml\").write_text(dvc_yaml, encoding=\"utf-8\")\n",
    "\n",
    "print((ROOT / \"dvc.yaml\").read_text(encoding=\"utf-8\")[:400] + \" ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1283707-5066-47bd-a73b-a0be49c615c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> dvc repro \n",
      " 'data\\raw\\UCI_Credit_Card.csv.dvc' didn't change, skipping\n",
      "Running stage 'prepare':\n",
      "> python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
      "\n",
      "{\n",
      "  \"model\": \"GradientBoostingClassifier\",\n",
      "  \"model_params\": {\n",
      "    \"learning_rate\": 0.1,\n",
      "    \"n_estimators\": 150\n",
      "  },\n",
      "  \"roc_auc\": 0.7705572956671517,\n",
      "  \"precision\": 0.6647230320699709,\n",
      "  \"recall\": 0.3436322532027129,\n",
      "  \"f1\": 0.45305514157973176\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "sh(\"dvc repro\")\n",
    "print((ROOT / \"models\" / \"metrics.json\").read_text(encoding=\"utf-8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e041954a-3a8f-441e-a168-a9acc509a5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> dvc remote add -d localstore ./dvcstore || echo already \n",
      " Setting 'localstore' as a default remote.\n",
      "\n",
      "> dvc push \n",
      " 1 file pushed\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='dvc push', returncode=0, stdout='1 file pushed\\n', stderr='')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создаю папку-хранилище\n",
    "(remote_dir := (ROOT / \"dvcstore\")).mkdir(exist_ok=True)\n",
    "# добавляю remote (если ещё не добавлен)\n",
    "sh(\"dvc remote add -d localstore ./dvcstore || echo already\")\n",
    "# пушу артефакты (модель, кэш датасета и т.д.) в локальное хранилище\n",
    "sh(\"dvc push\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebbcbac1-dccf-48d1-9805-93767681e725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> dvc exp run -S model.learning_rate=0.08 -S model.n_estimators=200 \n",
      " Reproducing experiment 'adunc-veil'\n",
      "'data\\raw\\UCI_Credit_Card.csv.dvc' didn't change, skipping\n",
      "Running stage 'prepare':\n",
      "> python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
      "\n",
      "> dvc exp run -S model.learning_rate=0.12 -S model.n_estimators=120 \n",
      " Reproducing experiment 'pushy-snip'\n",
      "'data\\raw\\UCI_Credit_Card.csv.dvc' didn't change, skipping\n",
      "Running stage 'prepare':\n",
      "> python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
      "\n",
      "> dvc exp run -S model.learning_rate=0.07 -S model.n_estimators=300 \n",
      " Reproducing experiment 'fifty-envy'\n",
      "'data\\raw\\UCI_Credit_Card.csv.dvc' didn't change, skipping\n",
      "Running stage 'prepare':\n",
      "> python src/data/make_dataset.py data/raw/UCI_Credit_Card.csv data/processed/\n",
      "\n",
      "> dvc exp show --no-timestamp --only-changed --include-params model.learning_rate,model.n_estimators --include-metrics roc_auc,precision,recall,f1 \n",
      " usage: dvc experiments show [-h] [-q | -v] [-A] [--rev <commit>] [-n <num>]\n",
      "                            [-a] [-T] [--no-pager] [--only-changed]\n",
      "                            [--drop <regex_pattern>] [--keep <regex_pattern>]\n",
      "                            [--param-deps] [--sort-by <metric/param>]\n",
      "                            [--sort-order {asc,desc}] [--sha] [--hide-failed]\n",
      "                            [--hide-queued] [--hide-workspace] [--json]\n",
      "                            [--csv] [--md] [--precision <n>] [-f]\n",
      "\n",
      "Print experiments.\n",
      "Documentation: <https://man.dvc.org/exp/show>\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -q, --quiet           Be quiet.\n",
      "  -v, --verbose         Be verbose.\n",
      "  -A, --all-commits     Show all experiments in the repository (overrides\n",
      "                        `--rev` and `--num`).\n",
      "  --rev <commit>        Show experiments derived from the specified `<commit>`\n",
      "                        as baseline (HEAD by default).\n",
      "  -n, --num <num>       Show experiments from the last `num` commits (first\n",
      "                        parents) starting from the `--rev` baseline. Give a\n",
      "                        negative value to include all first-parent commits\n",
      "                        (similar to `git log -n`).\n",
      "  -a, --all-branches    Show experiments derived from the tip of all Git\n",
      "                        branches.\n",
      "  -T, --all-tags        Show experiments derived from all Git tags.\n",
      "  --no-pager            Do not pipe output into a pager.\n",
      "  --only-changed        Only show metrics/params with values varying across\n",
      "                        the selected experiments.\n",
      "  --drop <regex_pattern>\n",
      "                        Remove the columns matching the specified regex\n",
      "                        pattern.\n",
      "  --keep <regex_pattern>\n",
      "                        Preserve the columns matching the specified regex\n",
      "                        pattern.\n",
      "  --param-deps          Show only params that are stage dependencies.\n",
      "  --sort-by <metric/param>\n",
      "                        Sort related experiments by the specified metric or\n",
      "                        param.\n",
      "  --sort-order {asc,desc}\n",
      "                        Sort order to use with --sort-by. Defaults to\n",
      "                        ascending ('asc').\n",
      "  --sha                 Always show git commit SHAs instead of branch/tag\n",
      "                        names.\n",
      "  --hide-failed         Hide failed experiments in the table.\n",
      "  --hide-queued         Hide queued experiments in the table.\n",
      "  --hide-workspace      Hide workspace row in the table.\n",
      "  --json                Print output in JSON format instead of a human-\n",
      "                        readable table.\n",
      "  --csv                 Print output in csv format instead of a human-readable\n",
      "                        table.\n",
      "  --md                  Show tabulated output in the Markdown format (GFM).\n",
      "  --precision <n>       Round metrics/params to `n` digits precision after the\n",
      "                        decimal point. Rounds to 5 digits by default.\n",
      "  -f, --force           Force re-collection of experiments instead of loading\n",
      "                        from exp cache.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='dvc exp show --no-timestamp --only-changed --include-params model.learning_rate,model.n_estimators --include-metrics roc_auc,precision,recall,f1', returncode=254, stdout=\"usage: dvc experiments show [-h] [-q | -v] [-A] [--rev <commit>] [-n <num>]\\n                            [-a] [-T] [--no-pager] [--only-changed]\\n                            [--drop <regex_pattern>] [--keep <regex_pattern>]\\n                            [--param-deps] [--sort-by <metric/param>]\\n                            [--sort-order {asc,desc}] [--sha] [--hide-failed]\\n                            [--hide-queued] [--hide-workspace] [--json]\\n                            [--csv] [--md] [--precision <n>] [-f]\\n\\nPrint experiments.\\nDocumentation: <https://man.dvc.org/exp/show>\\n\\noptions:\\n  -h, --help            show this help message and exit\\n  -q, --quiet           Be quiet.\\n  -v, --verbose         Be verbose.\\n  -A, --all-commits     Show all experiments in the repository (overrides\\n                        `--rev` and `--num`).\\n  --rev <commit>        Show experiments derived from the specified `<commit>`\\n                        as baseline (HEAD by default).\\n  -n, --num <num>       Show experiments from the last `num` commits (first\\n                        parents) starting from the `--rev` baseline. Give a\\n                        negative value to include all first-parent commits\\n                        (similar to `git log -n`).\\n  -a, --all-branches    Show experiments derived from the tip of all Git\\n                        branches.\\n  -T, --all-tags        Show experiments derived from all Git tags.\\n  --no-pager            Do not pipe output into a pager.\\n  --only-changed        Only show metrics/params with values varying across\\n                        the selected experiments.\\n  --drop <regex_pattern>\\n                        Remove the columns matching the specified regex\\n                        pattern.\\n  --keep <regex_pattern>\\n                        Preserve the columns matching the specified regex\\n                        pattern.\\n  --param-deps          Show only params that are stage dependencies.\\n  --sort-by <metric/param>\\n                        Sort related experiments by the specified metric or\\n                        param.\\n  --sort-order {asc,desc}\\n                        Sort order to use with --sort-by. Defaults to\\n                        ascending ('asc').\\n  --sha                 Always show git commit SHAs instead of branch/tag\\n                        names.\\n  --hide-failed         Hide failed experiments in the table.\\n  --hide-queued         Hide queued experiments in the table.\\n  --hide-workspace      Hide workspace row in the table.\\n  --json                Print output in JSON format instead of a human-\\n                        readable table.\\n  --csv                 Print output in csv format instead of a human-readable\\n                        table.\\n  --md                  Show tabulated output in the Markdown format (GFM).\\n  --precision <n>       Round metrics/params to `n` digits precision after the\\n                        decimal point. Rounds to 5 digits by default.\\n  -f, --force           Force re-collection of experiments instead of loading\\n                        from exp cache.\\n\", stderr='ERROR: unrecognized arguments: --no-timestamp --include-params model.learning_rate,model.n_estimators --include-metrics roc_auc,precision,recall,f1\\n')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# гоняю 3 эксперимента с разными гиперами (без ручного коммита)\n",
    "sh(\"dvc exp run -S model.learning_rate=0.08 -S model.n_estimators=200\")\n",
    "sh(\"dvc exp run -S model.learning_rate=0.12 -S model.n_estimators=120\")\n",
    "sh(\"dvc exp run -S model.learning_rate=0.07 -S model.n_estimators=300\")\n",
    "\n",
    "# показываю таблицу: метрики + параметры (оставляю только интересное)\n",
    "sh(\"dvc exp show --no-timestamp --only-changed \"\n",
    "   \"--include-params model.learning_rate,model.n_estimators \"\n",
    "   \"--include-metrics roc_auc,precision,recall,f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2d583c-08c9-4845-9d33-1475d6b4502a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (credit)",
   "language": "python",
   "name": "credit-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
